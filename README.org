* EpiClust
scmodule code [[https://github.com/KellisLab/scmodule][adapted]] for ATAC-seq, multiomics, and peak-gene linking

** To install
You may need to create a CONDA environment as specified in [[epiclust.yml]].

After dependencies are met, this sequence of commands installs the library.
#+BEGIN_SRC bash
git clone git@github.com:KellisLab/epiclust.git
cd epiclust && pip install .
#+END_SRC
** Preprocessing
Make sure your peaks are in an AnnData (H5AD) file.

Using a Gene accessiblity matrix (e.g. as estimated by [[file:scripts/epiclust_gene_estimation.py][epiclust_gene_estimation.py]]) helps aggregate nearby peaks better than by alone.
This helps even with multiomic ATAC+GEX: use pseudo triple-omic (Peaks, Gene Accessiblity, Gene Expression)
So, for combining these:
#+BEGIN_SRC python
from sklearn.feature_extraction.text import TfidfTransformer
import anndata
import scanpy as sc
### Use TF-IDF (non-logTF) on peak matrix
peaks.X = TfidfTransformer().fit_transform(peaks.X)
### Normalize peak matrix to 10000 counts per cell to facilitate integration with gene accessibility
sc.pp.normalize_total(peaks, target_sum=10000)
### Normalize gene accessibility to 10000 counts per cell
sc.pp.normalize_total(gacc, target_sum=10000)
### Normalize gene expression (if multi-omic GEX+ATAC) to 10000 counts per cell
sc.pp.normalize_total(gexp, target_sum=10000)
### Concatenate modalities
adata = anndata.concat({
  "Peaks": peaks,
  "Gene Expression": gexp, ### if multi-omic. else omit
  "Gene Accessibility": gacc
}, axis=1, label="feature_types", merge="same")
### Rename accessibility genes if expression genes are already present
adata.var_names_make_unique("-GAcc-")
### Log-scale
sc.pp.log1p(adata)
### Calculate QC metrics
sc.pp.calculate_qc_metrics(adata, inplace=True, percent_top=[])
### PCA
sc.pp.pca(adata, n_comps=100)
#+END_SRC
** multi-omic workflow (RECOMMENDED)
Note that the n_neighbors parameter can be changed, as n_neighbors is the per-batch number of neighbors
#+BEGIN_SRC python
import epiclust as ec
for power in np.linspace(0, 1, 5):
	print("Calculating power:", power)
	ec.fit(adata, power=power, margin="log1p_total_counts", batch="feature_types")
	ec.neighbors(adata, key_added="pow_%.2f" % power, n_neighbors=25) ### takes forever but worth it

vidx = ec.filter_varp(adata, ["pow_%.2f" % power for power in np.linspace(0, 1, 5)])
adata = adata[:, vidx].copy()
ec.leiden(adata, ["pow_%.2f" % power for power in np.linspace(0, 1, 5)], resolution=1., max_comm_size=2500)
#+END_SRC
** Peak-Gene / Peak-Peak / Gene-Gene linking sample workflow

#+BEGIN_SRC python
gtf = ec.gtf.load_gtf("gencode.gtf.gz")
dw = ec.gene_distance.distance_weight_all(peak_names_to_var(adata.var.index.values), gtf)
dw = dw.loc[dw["gene"].isin(adata.var.index.values), :]
links = {}
for power in np.linspace(0, 1, 5):
	print("Calculating power:", power)
	ec.fit(adata, power=power, margin="log1p_total_counts", batch="feature_types",
	       squared_correlation=True,
               covariates=["batch", "pmi", "log1p_total_counts"]) ### technical covariates in .obs
	links[power] = ec.linking(adata, dw["gene"].values, dw["peak"].values)

### TODO combine table
#+END_SRC
** single-omic workflow (DEPRECATED except for RNA-seq)
#+BEGIN_SRC python
import epiclust as ec
for power in np.linspace(0, 1, 5):
	print("Calculating power:", power)
	ec.fit(adata, power=power, margin="log1p_total_counts")
	ec.neighbors(adata, key_added="pow_%.2f" % power)

vidx = ec.filter_varp(adata, ["pow_%.2f" % power for power in np.linspace(0, 1, 5)])
adata = adata[:, vidx].copy()
ec.leiden(adata, ["pow_%.2f" % power for power in np.linspace(0, 1, 5)], resolution=1., max_comm_size=2500)
#+END_SRC
* TODO wishlist
1. use pcor for modules: see if VARM clusters by spline info
2. cleanup function that removes varm, uns
3. .leiden() without filtering giant matrix
4. automatic .neighbors() key_added labels based on power
5. recipes
6. batched gene_estimation for lower memory footprint
7. iterative expansion to rest of features
8. centrality-based module naming
